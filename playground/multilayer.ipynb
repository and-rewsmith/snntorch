{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.0114]], grad_fn=<AddmmBackward0>)\n",
      "Loss: 0.000130068336147815\n",
      "Gradients for first layer's forward weights: tensor([[ 6.1538e-05,  7.1619e-06, -6.2029e-05, -3.7185e-05, -1.5717e-04,\n",
      "          2.0723e-05,  6.9320e-05,  6.9700e-05, -2.6066e-06,  6.9380e-05],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-1.5739e-04, -1.8318e-05,  1.5865e-04,  9.5106e-05,  4.0199e-04,\n",
      "         -5.3004e-05, -1.7730e-04, -1.7827e-04,  6.6667e-06, -1.7745e-04],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-4.0344e-04, -4.6954e-05,  4.0666e-04,  2.4378e-04,  1.0304e-03,\n",
      "         -1.3586e-04, -4.5446e-04, -4.5696e-04,  1.7089e-05, -4.5485e-04],\n",
      "        [ 5.7654e-05,  6.7099e-06, -5.8114e-05, -3.4838e-05, -1.4725e-04,\n",
      "          1.9415e-05,  6.4945e-05,  6.5302e-05, -2.4421e-06,  6.5001e-05],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Network parameters\n",
    "timesteps = 10\n",
    "layers = 3\n",
    "input_size = 10\n",
    "hidden_size = 10  # Size of each hidden layer\n",
    "output_size = 1   # Output size for each timestep\n",
    "\n",
    "# Define the dense layer class that connects forward and backward\n",
    "class BidirectionalDenseLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BidirectionalDenseLayer, self).__init__()\n",
    "        self.backward_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.forward_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activations = torch.zeros(BATCH_SIZE, hidden_size)\n",
    "    \n",
    "    def forward(self, x_forward=None, x_backward=None):\n",
    "        h = torch.zeros(BATCH_SIZE, hidden_size)\n",
    "\n",
    "        if x_forward is not None:\n",
    "            # Forward propagation from the current layer's input\n",
    "            h_forward = self.forward_layer(x_forward)\n",
    "            h += h_forward\n",
    "        \n",
    "        # Backward connection from previous layer (if exists)\n",
    "        if x_backward is not None:\n",
    "            h_backward = self.backward_layer(x_backward)\n",
    "            h += h_backward\n",
    "        \n",
    "        self.activations = torch.relu(h)  # ReLU activation\n",
    "        return self.activations\n",
    "\n",
    "# Define the network with 3 layers and 10 timesteps\n",
    "class BiDirectionalNetwork(nn.Module):\n",
    "    def __init__(self, layers, input_size, hidden_size, output_size):\n",
    "        super(BiDirectionalNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList([BidirectionalDenseLayer(hidden_size, hidden_size) for _ in range(layers)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Loop over timesteps\n",
    "        for t in range(timesteps):\n",
    "            layer_activations = []\n",
    "            \n",
    "            # Forward pass through each layer\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                if i == 0:\n",
    "                    # First layer does not have a lower layer to connect to\n",
    "                    layer(x, self.layers[i+1].activations)\n",
    "                elif i == len(self.layers) - 1:\n",
    "                    layer(self.layers[i-1].activations, None)\n",
    "                else:\n",
    "                    # Layers above connect to both the previous layer and the current layer's forward pass\n",
    "                    layer(self.layers[i+1].activations, self.layers[i-1].activations)\n",
    "\n",
    "        # Output layer (optional for the last layer at each timestep)\n",
    "        outputs = self.output_layer(self.layers[-1].activations)  # Output from the last layer at the last timestep\n",
    "        \n",
    "        return outputs  # Return both output and activations for later gradient computation\n",
    "\n",
    "# Dummy input to simulate a sequence over 10 timesteps, with batch size = 2\n",
    "x = torch.randn(BATCH_SIZE, input_size)\n",
    "\n",
    "# Initialize the network\n",
    "network = BiDirectionalNetwork(layers, input_size, hidden_size, output_size)\n",
    "\n",
    "# Forward pass\n",
    "output = network(x)\n",
    "\n",
    "# Loss function and backpropagation (global backprop after all timesteps)\n",
    "criterion = nn.MSELoss()\n",
    "target = torch.zeros(1, 1)  # Dummy target for loss computation\n",
    "\n",
    "# Compute loss and backpropagate\n",
    "loss = criterion(output, target)\n",
    "loss.backward()  # This will compute gradients globally, considering all timesteps and layers\n",
    "\n",
    "# Display the output, loss, and gradients\n",
    "print(\"Output:\", output)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# Print gradients for the first layer's weights to demonstrate backpropagation\n",
    "print(\"Gradients for first layer's forward weights:\", network.layers[0].forward_layer.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Passed!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest Case 2 Passed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Run the tests\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m test_valid_mode_conv1d()\n",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36mtest_valid_mode_conv1d\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m# Perform convolution for each channel using numpy and compare\u001b[39;00m\n\u001b[1;32m     46\u001b[0m expected_result_channel_1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconvolve(input_tensor[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy(), kernel_tensor[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m expected_result_channel_2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconvolve(input_tensor[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mnumpy(), kernel_tensor[\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m expected_result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([expected_result_channel_1, expected_result_channel_2])\n\u001b[1;32m     50\u001b[0m \u001b[39m# Perform convolution using valid_mode_conv1d\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def valid_mode_conv1d(input_tensor, kernel_tensor):\n",
    "    # input_tensor: (batch, channels, num_steps)\n",
    "    # kernel_tensor: (channels, 1, kernel_size)\n",
    "\n",
    "    # Get dimensions\n",
    "    batch_size, in_channels, num_steps = input_tensor.shape\n",
    "    out_channels, _, kernel_size = kernel_tensor.shape\n",
    "    \n",
    "    # Perform convolution without padding for 'valid' mode\n",
    "    # Grouped convolution with groups=in_channels performs an independent conv per channel\n",
    "    conv_result = F.conv1d(input_tensor, kernel_tensor, groups=in_channels)\n",
    "    \n",
    "    return conv_result\n",
    "\n",
    "# Test function to compare PyTorch results with NumPy\n",
    "def test_valid_mode_conv1d():\n",
    "    # Test Case 1: Simple example\n",
    "    input_tensor = torch.tensor([[[1, 2, 3, 4]]], dtype=torch.float32)  # (batch=1, channels=1, num_steps=4)\n",
    "    kernel_tensor = torch.tensor([[[0.2, 0.5, 0.2]]], dtype=torch.float32)  # (channels=1, 1, kernel_size=3)\n",
    "    \n",
    "    # Expected result using numpy.convolve in 'valid' mode\n",
    "    I_t = input_tensor.numpy().flatten()\n",
    "    decay_filter = kernel_tensor.numpy().flatten()\n",
    "    expected_result = np.convolve(I_t, decay_filter, mode='valid')\n",
    "    \n",
    "    # Perform convolution using valid_mode_conv1d\n",
    "    result = valid_mode_conv1d(input_tensor, kernel_tensor).squeeze().numpy()\n",
    "    \n",
    "    # Assert that the results are close\n",
    "    assert np.allclose(result, expected_result), f\"Test Case 1 Failed: {result} != {expected_result}\"\n",
    "    print(\"Test Case 1 Passed!\")\n",
    "    \n",
    "    # Test Case 2: Multi-channel input, single input channel\n",
    "    input_tensor = torch.tensor([[[1, 2, 3, 4], [4, 3, 2, 1]]], dtype=torch.float32)  # (batch=1, channels=2, num_steps=4)\n",
    "    kernel_tensor = torch.tensor([[[0.2, 0.5, 0.2]], [[0.1, 0.4, 0.1]]], dtype=torch.float32)  # (channels=2, 1, kernel_size=3)\n",
    "    \n",
    "    # Perform convolution for each channel using numpy and compare\n",
    "    expected_result_channel_1 = np.convolve(input_tensor[0, 0].numpy(), kernel_tensor[0, 0].numpy(), mode='valid')\n",
    "    expected_result_channel_2 = np.convolve(input_tensor[0, 1].numpy(), kernel_tensor[1, 0].numpy(), mode='valid')\n",
    "    expected_result = np.stack([expected_result_channel_1, expected_result_channel_2])\n",
    "    \n",
    "    # Perform convolution using valid_mode_conv1d\n",
    "    result = valid_mode_conv1d(input_tensor, kernel_tensor).squeeze().numpy()\n",
    "    \n",
    "    # Assert that the results for each channel are close\n",
    "    assert np.allclose(result, expected_result), f\"Test Case 2 Failed: {result} != {expected_result}\"\n",
    "    print(\"Test Case 2 Passed!\")\n",
    "\n",
    "# Run the tests\n",
    "test_valid_mode_conv1d()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
